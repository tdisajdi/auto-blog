import os
import json
import time
from datetime import datetime, timedelta
import pytz
import requests
import feedparser
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import google.generativeai as genai

# --- í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ---
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
UNSPLASH_ACCESS_KEY = os.environ.get("UNSPLASH_ACCESS_KEY")
GMAIL_USER = os.environ.get("GMAIL_USER")
GMAIL_APP_PASSWORD = os.environ.get("GMAIL_APP_PASSWORD")

# Gemini ì„¤ì •
genai.configure(api_key=GEMINI_API_KEY)
MODEL_NAME = 'gemini-3-flash-preview'

HISTORY_FILE = "history.json"

# --- 1. ìœ í‹¸ë¦¬í‹°: ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ---
def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def save_history(history):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

def clean_old_history(history):
    # 30ì¼ ì§€ë‚œ íˆìŠ¤í† ë¦¬ëŠ” ì‚­ì œ
    now = datetime.now()
    cleaned = {}
    for link, date_str in history.items():
        try:
            date_obj = datetime.fromisoformat(date_str)
            if now - date_obj < timedelta(days=30):
                cleaned[link] = date_str
        except:
            pass
    return cleaned

# --- 2. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (ìµœê·¼ 7ì¼) ---
def get_articles_from_feeds(feed_urls, history):
    articles = []
    now = datetime.now()
    seven_days_ago = now - timedelta(days=7)
    
    for url in feed_urls:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            link = entry.link
            
            # 30ì¼ ë‚´ í¬ìŠ¤íŒ…í–ˆë˜ ê¸°ì‚¬ë©´ íŒ¨ìŠ¤
            if link in history:
                continue
            
            # ìµœê·¼ 7ì¼ ê¸°ì‚¬ë§Œ ìˆ˜ì§‘
            try:
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    pub_date = datetime.fromtimestamp(time.mktime(entry.published_parsed))
                    if pub_date < seven_days_ago:
                        continue
            except Exception:
                pass 
            
            articles.append({
                "title": entry.title,
                "link": link,
                "summary": entry.get('summary', '')[:500] 
            })
            
            # ìµœëŒ€ 15ê°œê¹Œì§€ë§Œ ìˆ˜ì§‘í•˜ì—¬ AI í† í° ì ˆì•½
            if len(articles) >= 15:
                return articles[:15]
                
    return articles[:15]

# --- 3. AI í¸ì§‘ì¥ ì„ ì • (Gemini) ---
def select_top_topics(articles, count=2, category_name="í…Œí¬"):
    if len(articles) <= count:
        return articles
        
    print(f">>> AI í¸ì§‘ì¥ì´ [{category_name}] ë¶„ì•¼ì—ì„œ ìµœì ì˜ ì£¼ì œ ì„ ì • ì¤‘...")
    model = genai.GenerativeModel(MODEL_NAME)
    
    prompt = f"""
    ë„ˆëŠ” '{category_name}' ë¶„ì•¼ ì „ë¬¸ ë¸”ë¡œê·¸ í¸ì§‘ì¥ì´ì•¼.
    ì•„ë˜ {len(articles)}ê°œì˜ ê¸°ì‚¬ í›„ë³´êµ° ì¤‘ì—ì„œ 'íˆ¬ì ê°€ì¹˜ê°€ ê°€ì¥ ë†’ê³  ì‹¬ì¸µ ë¶„ì„ì´ ê°€ëŠ¥í•œ' ê°€ì¥ ì¤‘ìš”í•œ ì£¼ì œ {count}ê°œë¥¼ ê³¨ë¼ì¤˜.
    ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì„ íƒí•œ ê¸°ì‚¬ì˜ ë²ˆí˜¸(1ë¶€í„° ì‹œì‘)ë§Œ ë‹´ê¸´ JSON ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•´ì¤˜. (ì˜ˆ: [1, 4])
    
    [ê¸°ì‚¬ í›„ë³´êµ°]
    """
    for i, a in enumerate(articles):
        prompt += f"{i+1}. {a['title']}\n"
        
    try:
        # JSON í˜•ì‹ìœ¼ë¡œ ì•ˆì •ì ì¸ ì¶œë ¥ì„ ìœ ë„
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        indices = json.loads(response.text)
        selected = [articles[i-1] for i in indices[:count]]
        return selected
    except Exception as e:
        print(f">>> ì£¼ì œ ì„ ì • AI ì˜¤ë¥˜ (ê¸°ë³¸ê°’ ì‚¬ìš©): {e}")
        return articles[:count]

# --- 4. ë¸”ë¡œê·¸ ì›ê³  ì‘ì„± ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (Gemini) ---
def generate_blog_content(news_list):
    print(f">>> Gemini(ìŠ¤í¬)ê°€ 5ë‹¨ê³„ ì‹¬ì¸µ ë¶„ì„ ê¸€ì„ ì“°ëŠ” ì¤‘...")
    model = genai.GenerativeModel(MODEL_NAME)
    
    news_info = ""
    for i, news in enumerate(news_list):
        news_info += f"\n[ì£¼ì œ {i+1}]\nì œëª©: {news['title']}\nìš”ì•½: {news['summary']}\në§í¬: {news['link']}\n"
        
    prompt = f"""
    ë„ˆëŠ” IT/íˆ¬ì ì „ë¬¸ ë¸”ë¡œê±° 'ìŠ¤í¬(spo)'ì•¼. ì•„ë˜ {len(news_list)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ë¬¶ì–´ì„œ í•˜ë‚˜ì˜ í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…ìœ¼ë¡œ ì‘ì„±í•´.
    
    {news_info}
    
    [ì‘ì„± ì¡°ê±´]
    1. ê¸€ ì œëª©ì€ ì œê³µëœ ì£¼ì œë“¤ì„ ì•„ìš°ë¥´ë©´ì„œ í´ë¦­ì„ ìœ ë„í•˜ë„ë¡ ë§¤ë ¥ì ìœ¼ë¡œ ì§€ì–´ì¤˜. (ê°€ì¥ ì²« ì¤„ì— <h1> íƒœê·¸ë¡œ ë‹¨ 1ë²ˆ ì‘ì„±)
    2. ì„œë¡ ì€ "ì•ˆë…•í•˜ì„¸ìš”! ë¯¸ë˜ë¥¼ ìŠ¤í¬ì¼ëŸ¬í•˜ëŠ” ìŠ¤í¬(spo)ì…ë‹ˆë‹¤."ë¡œ ì‹œì‘í•´.
    3. ê° ì£¼ì œë³„ë¡œ ì „ë¬¸ì ì´ë©´ì„œë„ ì‰½ê²Œ ì„¤ëª…í•˜ê³ , ë°˜ë“œì‹œ ì•„ë˜ 5ê°€ì§€ ì„¹ì…˜ì„ í¬í•¨í•´:
       - ë°°ê²½ ë° ê°œìš” (The Context): 3ì¤„ ìš”ì•½ ë¦¬ìŠ¤íŠ¸ (<ul>, <li> ì‚¬ìš©)
       - ê¸°ìˆ ì  ë©”ì»¤ë‹ˆì¦˜ (Technical Deep-Dive): ê¸°ìˆ  ì„¤ëª…ì„ ìœ„í•œ HTML <table> í¬í•¨
       - ì‹œì¥ íŒë„ ë° ê²½ìŸì‚¬ ë¶„ì„ (Market Dynamics): êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„° í¬í•¨
       - ë¦¬ìŠ¤í¬ ë° í•œê³„ì  (Risk Factors): ë¹„íŒì  ì‹œê°ì˜ ë¶„ì„
       - ìŠ¤í¬(spo)ì˜ ì¸ì‚¬ì´íŠ¸ (Actionable Insights): ì „ë¬¸ ë¶„ì„ê°€ë¡œì„œì˜ ë…ì ì œì–¸
    4. ê° ì£¼ì œë¥¼ ì„¤ëª…í•˜ëŠ” ì²« ë¶€ë¶„ì— ì´ë¯¸ì§€ê°€ ë“¤ì–´ê°ˆ ìœ„ì¹˜ì— ë”± 1ë²ˆì”© [IMAGE_PLACEHOLDER_{{ì£¼ì œë²ˆí˜¸}}] ë¼ê³  í‘œì‹œí•´. (ì´ {len(news_list)}ê°œì˜ í”Œë ˆì´ìŠ¤í™€ë”)
    5. ê²°ë¡ ì—ëŠ” "ë” ë§ì€ IT ì†Œì‹ì´ ê¶ê¸ˆí•˜ë‹¤ë©´ êµ¬ë…í•´ì£¼ì„¸ìš”!"ë¡œ ë§ˆë¬´ë¦¬í•´.
    6. ì „ì²´ ë‚´ìš©ì€ í‹°ìŠ¤í† ë¦¬ì— ë¶™ì—¬ë„£ì—ˆì„ ë•Œ ë°”ë¡œ ì˜ˆì˜ê²Œ ë³´ì´ë„ë¡ ëª¨ë“  ìŠ¤íƒ€ì¼ì„ inline-style(CSS)ë¡œ ì ìš©í•´. (ë°°ê²½ìƒ‰, í°íŠ¸ ìƒ‰ìƒ, ì—¬ë°± ë“± ê¹”ë”í•˜ê²Œ)
    7. <html>, <body>, ```html ê°™ì€ ë¶ˆí•„ìš”í•œ íƒœê·¸ëŠ” ì ˆëŒ€ ì“°ì§€ ë§ê³  <div> íƒœê·¸ë¡œ ì „ì²´ë¥¼ ê°ì‹¸ì„œ ìˆœìˆ˜ HTML ì½”ë“œë§Œ ì¤˜.
    """
    
    response = model.generate_content(prompt)
    html_content = response.text.replace("```html", "").replace("```", "").strip()
    
    # 4-1. ë©”ì¼ ì œëª© ë° ê²€ìƒ‰ìš© í‚¤ì›Œë“œ ë¶„ë¦¬ ì¶”ì¶œ
    meta_prompt = f"""
    ì•„ë˜ ë¸”ë¡œê·¸ ì›ê³ ë¥¼ ì½ê³ , 
    1) ë©”ì¼ ì œëª©ìœ¼ë¡œ ì“¸ë§Œí•œ ë©‹ì§„ ì œëª© (ì´ëª¨ì§€ í¬í•¨, "[ì¹´í…Œê³ ë¦¬ ë¶„ì„]" ì ‘ë‘ì‚¬ í¬í•¨)
    2) Unsplash ì´ë¯¸ì§€ ê²€ìƒ‰ìš© ì˜ë¬¸ í‚¤ì›Œë“œ {len(news_list)}ê°œ (ê° ì£¼ì œì˜ í•µì‹¬ì„ ë‹´ì€ 1ë‹¨ì–´ì§œë¦¬ ì˜ì–´ ë‹¨ì–´)
    ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì¤˜.
    
    í˜•ì‹ ì˜ˆì‹œ: 
    {{
        "mail_subject": "[ì¹´í…Œê³ ë¦¬ ë¶„ì„] ğŸš€ ì• í”Œê³¼ êµ¬ê¸€ì˜ AI ì „ìŸì´ ë°”ì´ì˜¤ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥",
        "keywords": ["apple", "biotech"]
    }}
    
    ì›ê³ :
    {html_content[:1500]}
    """
    try:
        meta_res = model.generate_content(meta_prompt, generation_config={"response_mime_type": "application/json"})
        meta_data = json.loads(meta_res.text)
    except Exception:
        meta_data = {"mail_subject": "[ì¹´í…Œê³ ë¦¬ ë¶„ì„] ì˜¤ëŠ˜ì˜ ë”¥ë‹¤ì´ë¸Œ ë¦¬í¬íŠ¸", "keywords": ["technology", "innovation"]}
        
    return html_content, meta_data

# --- 5. ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ì‚½ì… (Unsplash) ---
def add_images_to_html(html_content, keywords):
    print(f">>> ì¶”ì¶œëœ í‚¤ì›Œë“œ({keywords})ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ì‚½ì… ì¤‘...")
    for i, keyword in enumerate(keywords):
        url = f"[https://api.unsplash.com/search/photos?query=](https://api.unsplash.com/search/photos?query=){keyword}&per_page=1&orientation=landscape&client_id={UNSPLASH_ACCESS_KEY}"
        placeholder = f"[IMAGE_PLACEHOLDER_{i+1}]"
        
        try:
            response = requests.get(url).json()
            results = response.get('results', [])
            
            if results:
                img_url = results[0]['urls']['regular']
                img_tag = f'<div style="text-align:center; margin: 30px 0;"><img src="{img_url}" style="width:100%; max-width:700px; border-radius:12px; box-shadow: 0 4px 10px rgba(0,0,0,0.1);"></div>'
                html_content = html_content.replace(placeholder, img_tag)
            else:
                html_content = html_content.replace(placeholder, "")
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            html_content = html_content.replace(placeholder, "")
            
    # ë‚¨ì•„ìˆëŠ” í”Œë ˆì´ìŠ¤í™€ë” ì”ì¬ê°€ ìˆë‹¤ë©´ ì •ë¦¬
    for i in range(1, 6):
         html_content = html_content.replace(f"[IMAGE_PLACEHOLDER_{i}]", "")
         
    return html_content

# --- 6. ì´ë©”ì¼ ë°œì†¡ (ì†ŒìŠ¤ì½”ë“œ + ë¯¸ë¦¬ë³´ê¸° í…œí”Œë¦¿) ---
def send_email(subject, html_body):
    print(f">>> ì´ë©”ì¼ ì „ì†¡ ì‹œì‘: {subject}")
    msg = MIMEMultipart()
    msg['From'] = GMAIL_USER
    msg['To'] = GMAIL_USER
    msg['Subject'] = subject

    # HTML ì½”ë“œë¥¼ í…ìŠ¤íŠ¸ë°•ìŠ¤ì— ë„£ê¸° ìœ„í•´ ì¹˜í™˜
    escaped_html = html_body.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
    
    email_content = f"""
    <div style="font-family: 'Apple SD Gothic Neo', sans-serif; max-width: 850px; margin: auto; color: #333;">
        <h2 style="color: #2c3e50; border-bottom: 2px solid #eee; padding-bottom: 10px;">ğŸ“ ì˜¤ëŠ˜ì˜ í¬ìŠ¤íŒ… ì›ê³ ê°€ ë„ì°©í–ˆìŠµë‹ˆë‹¤.</h2>
        <p style="font-size: 14px; color: #555;">ì•„ë˜ ì†ŒìŠ¤ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ í‹°ìŠ¤í† ë¦¬ <b>[HTML ëª¨ë“œ]</b>ì— ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.</p>
        
        <textarea readonly style="width: 100%; height: 300px; padding: 15px; background-color: #f8f9fa; border: 1px solid #ced4da; border-radius: 8px; font-family: monospace; font-size: 13px; color: #d63384; line-height: 1.5;">
{escaped_html}
        </textarea>
        
        <hr style="margin: 50px 0; border: 0; border-top: 2px dashed #ddd;">
        
        <h2 style="color: #2c3e50; text-align: center; margin-bottom: 30px;">ğŸ‘€ ì‹¤ì œ ë¸”ë¡œê·¸ ë¯¸ë¦¬ë³´ê¸° ğŸ‘€</h2>
        <div style="border: 1px solid #e9ecef; padding: 30px; border-radius: 12px; background-color: #fff; box-shadow: 0 4px 15px rgba(0,0,0,0.05);">
            {html_body}
        </div>
    </div>
    """

    msg.attach(MIMEText(email_content, 'html'))

    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
            server.login(GMAIL_USER, GMAIL_APP_PASSWORD)
            server.send_message(msg)
        print(">>> âœ… ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ!")
    except Exception as e:
        print(f">>> âŒ ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

# --- ë©”ì¸ ì‹¤í–‰ ---
def main():
    # 1. KST ê¸°ì¤€ ìš”ì¼ í™•ì¸ (0: ì›”ìš”ì¼ ~ 6: ì¼ìš”ì¼)
    kst = pytz.timezone('Asia/Seoul')
    now_kst = datetime.now(kst)
    weekday = now_kst.weekday() 
    
    print(f"\n========== ìŠ¤í¬(spo) ìë™í™” ë´‡ ==========")
    print(f">>> KST í˜„ì¬ ì‹œê°„: {now_kst.strftime('%Y-%m-%d %H:%M:%S')}")
    
    history = load_history()
    history = clean_old_history(history)
    selected_news = []
    
    # 2. ìš”ì¼ì— ë”°ë¥¸ ê¸°ì‚¬ ìˆ˜ì§‘ ë° ì„ ì •
    if weekday == 0:  # ì›”ìš”ì¼
        print(">>> [ì›”ìš”ì¼ ëª¨ë“œ] í…Œí¬(TECH) ì¹´í…Œê³ ë¦¬ ê¸°ì‚¬ ìˆ˜ì§‘ (2ê°œ)")
        tech_feeds = [
            "[https://www.theverge.com/rss/index.xml](https://www.theverge.com/rss/index.xml)",
            "[https://techcrunch.com/feed/](https://techcrunch.com/feed/)"
        ]
        articles = get_articles_from_feeds(tech_feeds, history)
        selected_news = select_top_topics(articles, count=2, category_name="í…Œí¬(TECH)")
        
    else:  # í™”~ì¼ìš”ì¼
        print(">>> [í™”~ì¼ ëª¨ë“œ] ë°”ì´ì˜¤(BIO) & íŠ¹í—ˆ(PATENT) ìˆ˜ì§‘ (ê° 1ê°œ)")
        bio_feeds = [
            "[https://news.google.com/rss/search?q=Biotech+OR+%22FDA+approval%22+OR+%22clinical+trials%22&hl=en-US&gl=US&ceid=US:en](https://news.google.com/rss/search?q=Biotech+OR+%22FDA+approval%22+OR+%22clinical+trials%22&hl=en-US&gl=US&ceid=US:en)"
        ]
        patent_feeds = [
            "[https://news.google.com/rss/search?q=Patent+OR+%22tech+innovation%22+OR+%22future+tech%22&hl=en-US&gl=US&ceid=US:en](https://news.google.com/rss/search?q=Patent+OR+%22tech+innovation%22+OR+%22future+tech%22&hl=en-US&gl=US&ceid=US:en)"
        ]
        
        bio_articles = get_articles_from_feeds(bio_feeds, history)
        patent_articles = get_articles_from_feeds(patent_feeds, history)
        
        bio_top = select_top_topics(bio_articles, count=1, category_name="ë°”ì´ì˜¤(BIO)")
        patent_top = select_top_topics(patent_articles, count=1, category_name="íŠ¹í—ˆ(PATENT)")
        
        selected_news.extend(bio_top)
        selected_news.extend(patent_top)

    if not selected_news:
        print(">>> ì¡°ê±´ì— ë§ëŠ” ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 3. ê¸€ ì“°ê¸° ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    raw_html, meta_data = generate_blog_content(selected_news)
    
    # 4. ì´ë¯¸ì§€ ë„£ê¸° (ì¶”ì¶œëœ í‚¤ì›Œë“œ ì‚¬ìš©)
    final_html = add_images_to_html(raw_html, meta_data.get("keywords", []))
    
    # 5. ë©”ì¼ ë³´ë‚´ê¸° (ë¯¸ë¦¬ë³´ê¸° í¬í•¨)
    mail_subject = meta_data.get("mail_subject", "[ì¹´í…Œê³ ë¦¬ ë¶„ì„] ìŠ¤í¬(spo)ì˜ ìµœì‹  ë”¥ë‹¤ì´ë¸Œ ë¦¬í¬íŠ¸")
    send_email(mail_subject, final_html)
    
    # 6. íˆìŠ¤í† ë¦¬ ì €ì¥
    iso_now = datetime.now().isoformat()
    for news in selected_news:
        history[news['link']] = iso_now
    save_history(history)
    print("========== ì‘ì—… ì™„ë£Œ ==========\n")

if __name__ == "__main__":
    main()
